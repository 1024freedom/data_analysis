导入库 (Import Libraries):

numpy 和 pandas: 用于数据处理和分析。

matplotlib.pyplot 和 seaborn: 用于数据可视化。

warnings, time, datetime, joblib: 其他辅助库，warnings 用于忽略不必要的警告。

数据加载与合并 (Data Loading and Merging):

pd.read_csv(): 读取三个数据文件：

data/data1.csv: 包含公司股票代码和所属行业类别。

data/data2.csv: 包含主要的财务数据。

pd.read_excel(): 读取 data/data3.xlsx，这个文件包含了财务数据中各个字段的中文含义和单位。

创建字段含义字典 (fields): 将 df_fields 中的字段名与其含义和单位对应起来，方便后续查看。

数据合并 (pd.merge):

将 df_category（行业类别）的数据合并到 df_all（财务数据）中，基于共同的股票代码 TICKER_SYMBOL。

调整合并后的列顺序，将 所属行业 列插入到 df_all 的第二列，并重命名为 INDUSTRY。

更新 fields 字典，加入 INDUSTRY 字段的含义。

初步数据检视:

df_all.head(): 显示合并后 DataFrame 的前几行。

df_all.shape: 显示 DataFrame 的维度（行数和列数）。

df_all['FLAG'].value_counts(): 查看目标变量 FLAG（可能表示是否存在财务风险，0为无风险，1为有风险）的分布情况。

df_all.dtypes: 显示各列的数据类型。

数据探索 (Data Exploration):

筛选行业数据:

df = df_all[df_all['INDUSTRY'] == '制造业']: 从 df_all 中筛选出 INDUSTRY 为 "制造业" 的数据，赋值给新的 DataFrame df。这是因为项目目标是针对制造业上市公司。

数据去重:

df.drop_duplicates(inplace=True): 删除 df 中的重复行。

df = df.drop_duplicates().reset_index(drop=True): 再次去重（虽然在脚本中是冗余的，但保留了 Notebook 中的操作），并重置索引。

数据分布可视化:

plt.rcParams: 设置 matplotlib 的参数，以支持中文显示和解决负号显示问题。

numeric_cols_test: 定义了一个包含部分数值型列名的列表，用于后续的分布可视化。

循环绘制直方图和箱线图:

遍历 numeric_cols_test 中的每一列。

为每一列创建一个包含两个子图的图形：

子图1: 使用 seaborn.histplot() 绘制该列数据的直方图（带核密度估计）。

子图2: 使用 seaborn.boxplot() 绘制该列数据的箱线图。

设置图表标题，使用 fields 字典获取字段的中文含义。

plt.show(): 显示图表。

plot_numeric_distribution 函数: 定义了一个更通用的函数，用于批量绘制数值型变量的直方图。

调用 plot_numeric_distribution(df, numeric_cols_test) 再次对选定的数值型变量进行可视化。

描述性统计:

df.describe(): 显示数值型列的描述性统计信息（如均值、标准差、最小值、最大值等）。

numeric_cols = numeric.columns: 获取所有数值型列的名称。

df.describe(include='O'): 显示对象类型（通常是字符串）列的描述性统计信息（如计数、唯一值数量、最常见值及其频率）。

nominal_cols = nominal.columns: 获取所有对象类型列的名称。

循环绘制分类型字段的柱状图:

遍历 nominal_cols 中的每一列。

使用 seaborn.countplot() 绘制每一列的计数柱状图，展示不同类别的频率。

设置图表标题和 x 轴标签旋转。

plt.show(): 显示图表。

缺失值分析 (Missing Value Analysis):

df.isnull().sum(): 统计 df 中每一列的缺失值数量。

import missingno: 导入 missingno 库，这是一个专门用于可视化缺失数据的库。

missingno.matrix(df, figsize=(15, 10)): 使用矩阵图可视化整个 DataFrame 的缺失值模式。

miss_data_count 函数: 定义了一个函数，用于创建一个包含字段名、缺失值数量、缺失率和数据类型的 DataFrame，方便查看缺失情况。

调用 miss_data_count(df) 生成并显示缺失值统计表 data_null。

数据预处理 (Data Preprocessing):

缺失值处理 (Missing Value Handling):

定义处理策略:

dropna_cols: 用于存储缺失率大于等于 70% 的列名，这些列将被删除。

fill0_cols: 用于存储缺失率小于 70% 且大于 0 的列名（不包括目标变量 FLAG，除非 FLAG 的缺失率也小于 70%），这些列的缺失值将被填充为 0。

执行删除和填充:

遍历 data_null 表，根据缺失率将列名分配到 dropna_cols 或 fill0_cols。

特别处理目标变量 FLAG 的缺失：如果 FLAG 有缺失值且缺失率小于 70%，则也将其加入 fill0_cols。

df.drop(columns=dropna_cols, inplace=True): 删除缺失率过高的列。

df[fill0_cols] = df[fill0_cols].fillna(value=0): 将选定列的缺失值填充为 0。

再次处理 FLAG 的缺失: 如果 FLAG 列仍然存在 NaN 值（例如，如果它没有被包含在 fill0_cols 中），则删除这些包含 NaN 的行。

df.head() 和 df.shape: 显示处理后 DataFrame 的情况。

创建 df0: df0 = df.copy() 创建一个 df 的副本，用于后续的噪声处理和数据变换。

噪声数据处理 (Noise Data Handling):

bin_smooth 函数 (分箱平滑):

定义了一个函数，首先使用 pd.cut() 对指定列进行等宽分箱。

然后根据指定的方法（均值、中位数）计算每个箱内的平滑值。

将原始值映射到对应的平滑值。

示例: 对 BIZ_TAX_SURCHG（营业税金及附加）列进行均值分箱平滑。

regression_smooth 函数 (回归平滑):

这个函数在原始 Notebook 中是 raw 单元格，没有被执行。它概念性地描述了如何使用线性回归来预测和填充缺失值，但实际执行需要更具体的特征选择和模型训练步骤。脚本中将其注释掉了。

数据变换 (Data Transformation):

moving_average_smooth 函数 (移动平均光滑):

定义了一个函数，使用 rolling().mean() 计算指定列的移动平均值来平滑数据。

示例: 对 T_SH_EQUITY（所有者权益）列进行窗口大小为 3 的移动平均光滑。

generalize_data 函数 (数据泛化):

定义了一个函数，使用 pd.cut() 将数值型数据转换为类别型数据（分箱）。

示例: 将 N_INCOME（净利润）泛化为 "小型企业"、"中型企业"、"大型企业" 三类。

reduce_numerical 函数 (数值规约 - 对数变换):

定义了一个函数，对指定列进行 np.log1p（即 log(1+x)）变换，常用于处理右偏数据。

示例: 对 NOPERATE_INCOME（营业外收入）列进行对数变换。

pca_reduction 函数 (PCA 降维):

定义了一个函数，使用主成分分析 (PCA) 对选定的数值型特征进行降维。

首先使用 StandardScaler 对数据进行标准化。

然后使用 PCA 进行降维，可以指定保留的主成分数量或保留的方差比例。

示例: 对 df0 中所有数值型列（除了 FLAG）进行 PCA 降维，保留 95% 的方差。

特征选择 (Feature Selection):

filter_feature_selection 函数 (过滤式特征选择):

定义了一个函数，使用 SelectKBest 和 f_classif (ANOVA F-value) 从特征集中选择最重要的 k 个特征。

示例: 从 df0 的数值型特征中选择与目标变量 FLAG 最相关的 10 个特征。

在选择前，定义了 drop_cols 列表，包含需要从特征集中移除的列（如ID、文本类别的原始列以及一些中间生成的列）。

cols_for_X 列表确保只选择数值型且未被排除的列作为特征。